As introduced by Aral, Georgescu-Roegen, and West, data science has provided metrics previously unseen or imperceptible. Current day applications range from detecting conditions in medical imaging to crafting social media trends and personalized suggestions to reading gender biases in classic texts. The applications continue to expand further due to the ability to either quickly parse data or utilize computing to handle relationships between multiple variables. But the field’s strength in providing metrics is its own downfall—the effects of insights from data science are extremely reliant on its utilization, which is leading towards social and economic stratification through unequal distribution of technology and lack of regulation.
On a daily basis, we hand out data freely. Stories of sifting through trashed receipts have realized in more sinister ways through search histories, geotagging, and background app activity. It’s reasonable to conclude that if the data is out and available to whomever regardless, what does the advent of data science change? The issue therein lies with who receives our data, and algorithms have enabled insights to be drawn from seemingly disparate pieces of activity. Spotify’s music algorithm includes variables that one might expect: a song’s rhythm, tempo, and genre, what your friends listen to, what time of day you choose certain songs (3am instrumentals vs. 10pm EDM). Apple Music exists as a service that Apple provides and has the ability to curates your recommended songs not only off of your listening habits, but also any information Apple may collect from your phone—those same search histories and geotags. As a means to create metrics, data science cannot answer whether the tradeoff in privacy is worth it when we craft our newest running playlist. Neither have our governments. 
A significant amount of data is given to a few select companies—Apple, Google, Twitter, Amazon—the tech giants that we recognize in the news. Creating insights through data science is reliant primarily on two input factors, the physical capital required to complete heavy processing and a sizable dataset to generalize or specify results as required. Smaller competitors such as DuckDuckGo and Ecosia lack both input factors and cycle into a positive feedback loop that make them less competitive. Furthermore, competitors not only have the ability to demand increases in quality but also introduce elements consumers care about, in this case data privacy and environmental impact, that Google has not been forced to evaluate. The recent anti-trust lawsuit that the Justice Department has filed is promising in terms of government regulation, but the slower rate of policymaking has not been able to effectively regulate advances across Silicon Valley, much less a relatively newer field such as data science. The ability of large firms to act upon their data science insights has resulted in economic stratification and greater social inequality.
This is not to say data science ought to be discarded. It has produced invaluable humanitarian work in disaster relief and more recently generating bioinformatics about COVID-19 and the advances made should not be reversed. Rather, government regulation needs to identify how to protect user privacy and act as a neutral third party. With the history of the PATRIOT Act and strong ties to Amazon Web Services, government action needs to not only reevaluate legislation regarding Tech Giants but also its own practices.
